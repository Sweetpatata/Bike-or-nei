{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688021ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten, LSTM\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab1c7e",
   "metadata": {},
   "source": [
    "# Data & Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4ac6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/frederickjohannson/code/Sweetpatata/bike-or-nei/data_all_cleaned.csv')\n",
    "df = df.drop(columns=['Trips_in','Trips_out', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02034933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293762, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Station_Id', 'Date', 'In_Out', 'temp_min', 'temp_max',\n",
       "       'wind_speed_avg', 'rainfall_total', 'snow_total', 'day_of_week_0',\n",
       "       'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4',\n",
       "       'day_of_week_5', 'day_of_week_6', 'Month_1', 'Month_2', 'Month_3',\n",
       "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
       "       'Month_10', 'Month_11', 'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541ea7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'In_Out'\n",
    "N_TARGETS = 1\n",
    "N_FEATURES = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311a2d3",
   "metadata": {},
   "source": [
    "# Extracting Data for one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f117d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Station_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Trips_in</th>\n",
       "      <th>Trips_out</th>\n",
       "      <th>In_Out</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>wind_speed_avg</th>\n",
       "      <th>rainfall_total</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183879</td>\n",
       "      <td>556</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>11.21</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.620833</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177199</td>\n",
       "      <td>550</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.620833</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178251</td>\n",
       "      <td>551</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.620833</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179453</td>\n",
       "      <td>552</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.620833</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Station_Id        Date  Trips_in  Trips_out  In_Out  temp_min  \\\n",
       "0      183879         556  2019-04-02         1          1       0     -2.04   \n",
       "1           0         377  2019-04-03        12         15      -3     -2.79   \n",
       "2      177199         550  2019-04-03         6         11      -5     -2.79   \n",
       "3      178251         551  2019-04-03        68         40      28     -2.79   \n",
       "4      179453         552  2019-04-03        22         17       5     -2.79   \n",
       "\n",
       "   temp_max  wind_speed_avg  rainfall_total  ...  Month_3  Month_4  Month_5  \\\n",
       "0     11.21        4.633333            0.00  ...      0.0      1.0      0.0   \n",
       "1      6.61        4.620833            1.71  ...      0.0      1.0      0.0   \n",
       "2      6.61        4.620833            1.71  ...      0.0      1.0      0.0   \n",
       "3      6.61        4.620833            1.71  ...      0.0      1.0      0.0   \n",
       "4      6.61        4.620833            1.71  ...      0.0      1.0      0.0   \n",
       "\n",
       "   Month_6  Month_7  Month_8  Month_9  Month_10  Month_11  Month_12  \n",
       "0      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "1      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "2      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "3      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "4      0.0      0.0      0.0      0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603fc7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1269"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.groupby('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a77afaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "station_list = []\n",
    "for station in df['Station_Id'].unique():\n",
    "    df_station = df[df['Station_Id'] == station]\n",
    "    df_station.set_index('Date', inplace=True)\n",
    "    df_list.append(df_station)\n",
    "    station_list.append(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f3ce8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89e1ab00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Id</th>\n",
       "      <th>In_Out</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>wind_speed_avg</th>\n",
       "      <th>rainfall_total</th>\n",
       "      <th>snow_total</th>\n",
       "      <th>day_of_week_0</th>\n",
       "      <th>day_of_week_1</th>\n",
       "      <th>day_of_week_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-02</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>11.21</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03</th>\n",
       "      <td>556</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.620833</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>15.38</td>\n",
       "      <td>4.389583</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05</th>\n",
       "      <td>556</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>12.05</td>\n",
       "      <td>6.741667</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06</th>\n",
       "      <td>556</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>13.98</td>\n",
       "      <td>3.275000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-27</th>\n",
       "      <td>556</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.21</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.071250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28</th>\n",
       "      <td>556</td>\n",
       "      <td>3</td>\n",
       "      <td>7.69</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.264583</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29</th>\n",
       "      <td>556</td>\n",
       "      <td>-3</td>\n",
       "      <td>4.06</td>\n",
       "      <td>16.58</td>\n",
       "      <td>3.171667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>9.83</td>\n",
       "      <td>1.096667</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>556</td>\n",
       "      <td>1</td>\n",
       "      <td>6.02</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.132917</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1192 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Station_Id  In_Out  temp_min  temp_max  wind_speed_avg  \\\n",
       "Date                                                                 \n",
       "2019-04-02         556       0     -2.04     11.21        4.633333   \n",
       "2019-04-03         556      -5     -2.79      6.61        4.620833   \n",
       "2019-04-04         556       0     -1.76     15.38        4.389583   \n",
       "2019-04-05         556      -7     -1.41     12.05        6.741667   \n",
       "2019-04-06         556      -2     -0.49     13.98        3.275000   \n",
       "...                ...     ...       ...       ...             ...   \n",
       "2022-10-27         556      -1      5.21     13.72        3.071250   \n",
       "2022-10-28         556       3      7.69     14.30        2.264583   \n",
       "2022-10-29         556      -3      4.06     16.58        3.171667   \n",
       "2022-10-30         556       0      0.21      9.83        1.096667   \n",
       "2022-10-31         556       1      6.02     14.30        2.132917   \n",
       "\n",
       "            rainfall_total  snow_total  day_of_week_0  day_of_week_1  \\\n",
       "Date                                                                   \n",
       "2019-04-02            0.00        0.00            0.0            1.0   \n",
       "2019-04-03            1.71        0.60            0.0            0.0   \n",
       "2019-04-04            0.00        0.00            0.0            0.0   \n",
       "2019-04-05            0.39        0.50            0.0            0.0   \n",
       "2019-04-06            1.00        0.88            0.0            0.0   \n",
       "...                    ...         ...            ...            ...   \n",
       "2022-10-27            0.10        0.00            0.0            0.0   \n",
       "2022-10-28            3.01        0.00            0.0            0.0   \n",
       "2022-10-29            0.00        0.00            0.0            0.0   \n",
       "2022-10-30            0.19        0.00            0.0            0.0   \n",
       "2022-10-31            0.60        0.00            1.0            0.0   \n",
       "\n",
       "            day_of_week_2  ...  Month_3  Month_4  Month_5  Month_6  Month_7  \\\n",
       "Date                       ...                                                \n",
       "2019-04-02            0.0  ...      0.0      1.0      0.0      0.0      0.0   \n",
       "2019-04-03            1.0  ...      0.0      1.0      0.0      0.0      0.0   \n",
       "2019-04-04            0.0  ...      0.0      1.0      0.0      0.0      0.0   \n",
       "2019-04-05            0.0  ...      0.0      1.0      0.0      0.0      0.0   \n",
       "2019-04-06            0.0  ...      0.0      1.0      0.0      0.0      0.0   \n",
       "...                   ...  ...      ...      ...      ...      ...      ...   \n",
       "2022-10-27            0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "2022-10-28            0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "2022-10-29            0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "2022-10-30            0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "2022-10-31            0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "            Month_8  Month_9  Month_10  Month_11  Month_12  \n",
       "Date                                                        \n",
       "2019-04-02      0.0      0.0       0.0       0.0       0.0  \n",
       "2019-04-03      0.0      0.0       0.0       0.0       0.0  \n",
       "2019-04-04      0.0      0.0       0.0       0.0       0.0  \n",
       "2019-04-05      0.0      0.0       0.0       0.0       0.0  \n",
       "2019-04-06      0.0      0.0       0.0       0.0       0.0  \n",
       "...             ...      ...       ...       ...       ...  \n",
       "2022-10-27      0.0      0.0       1.0       0.0       0.0  \n",
       "2022-10-28      0.0      0.0       1.0       0.0       0.0  \n",
       "2022-10-29      0.0      0.0       1.0       0.0       0.0  \n",
       "2022-10-30      0.0      0.0       1.0       0.0       0.0  \n",
       "2022-10-31      0.0      0.0       1.0       0.0       0.0  \n",
       "\n",
       "[1192 rows x 26 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d0ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d958dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_377 = df[df['Station_Id'] == 377]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903756b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station_377.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276da439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_377 = df_station_377.drop(columns=['Trips_in','Trips_out', 'Unnamed: 0', 'Station_Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e60159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_377.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79e9cc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In_Out              int64\n",
       "temp_min          float64\n",
       "temp_max          float64\n",
       "wind_speed_avg    float64\n",
       "rainfall_total    float64\n",
       "snow_total        float64\n",
       "day_of_week_0     float64\n",
       "day_of_week_1     float64\n",
       "day_of_week_2     float64\n",
       "day_of_week_3     float64\n",
       "day_of_week_4     float64\n",
       "day_of_week_5     float64\n",
       "day_of_week_6     float64\n",
       "Month_1           float64\n",
       "Month_2           float64\n",
       "Month_3           float64\n",
       "Month_4           float64\n",
       "Month_5           float64\n",
       "Month_6           float64\n",
       "Month_7           float64\n",
       "Month_8           float64\n",
       "Month_9           float64\n",
       "Month_10          float64\n",
       "Month_11          float64\n",
       "Month_12          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station_377.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff5c1d",
   "metadata": {},
   "source": [
    "# Folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf10ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_LENGTH = 30 # total days 1269 / total months 43\n",
    "FOLD_STRIDE = 14\n",
    "TRAIN_TEST_RATIO = 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "739932f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(\n",
    "    df,\n",
    "    fold_length,\n",
    "    fold_stride):\n",
    "    '''\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "    \n",
    "    Returns a list of folds, each as a DataFrame\n",
    "    '''\n",
    "    \n",
    "    folds = []\n",
    "    for idx in range(0, len(df), fold_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (idx + fold_length) > len(df):\n",
    "            break\n",
    "        fold = df.iloc[idx:idx + fold_length, :]\n",
    "        folds.append(fold)#(np.asarray(fold).astype('float32'))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6a426b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function generated 84 folds.\n",
      "Each fold has a shape equal to (30, 25).\n"
     ]
    }
   ],
   "source": [
    "folds = get_folds(df_station_377, FOLD_LENGTH, FOLD_STRIDE)\n",
    "\n",
    "print(f'The function generated {len(folds)} folds.')\n",
    "print(f'Each fold has a shape equal to {folds[0].shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e87b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 5\n",
    "output_length = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9133219",
   "metadata": {},
   "source": [
    "# Test-train split (one fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "237ad72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fold,\n",
    "                     train_test_ratio,\n",
    "                     input_length):\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe (fold_train, fold_test)\n",
    "    from which one can sample (X,y) sequences.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))   \n",
    "    '''\n",
    "    # TRAIN SET\n",
    "    # ======================\n",
    "    last_train_idx = round(train_test_ratio * len(fold))\n",
    "    fold_train = fold.iloc[0:last_train_idx, :]\n",
    "\n",
    "    # TEST SET\n",
    "    # ======================    \n",
    "    first_test_idx = last_train_idx - input_length\n",
    "    fold_test = fold.iloc[first_test_idx:, :]\n",
    "\n",
    "    return (fold_train, fold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a55092",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_train, fold_test) = train_test_split(folds[0], TRAIN_TEST_RATIO, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946452cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xi_yi(\n",
    "    fold, \n",
    "    input_length, \n",
    "    output_length):\n",
    "    '''\n",
    "    - given a fold, it returns one sequence (X_i, y_i)\n",
    "    - with the starting point of the sequence being chosen at random\n",
    "    '''\n",
    "    first_possible_start = 0\n",
    "    last_possible_start = len(fold) - (input_length + output_length) + 1\n",
    "    random_start = np.random.randint(first_possible_start, last_possible_start)\n",
    "    X_i = fold.iloc[random_start:random_start+input_length]    \n",
    "    y_i = fold.iloc[random_start+input_length:\n",
    "                  random_start+input_length+output_length][[TARGET]]\n",
    "    \n",
    "    return (X_i, y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8635a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i, y_train_i = get_Xi_yi(fold_train, input_length, output_length)\n",
    "X_test_i, y_test_i = get_Xi_yi(fold_test, input_length, output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3c0bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(\n",
    "    fold,\n",
    "    number_of_sequences,\n",
    "    input_length,\n",
    "    output_length\n",
    "    ):\n",
    "    \n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(number_of_sequences):\n",
    "        (Xi, yi) = get_Xi_yi(fold, input_length, output_length)\n",
    "        X.append(Xi)\n",
    "        y.append(yi)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f2374e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 60 # number_of_sequences_train\n",
    "N_TEST =  40 # number_of_sequences_test\n",
    "\n",
    "X_train, y_train = get_X_y(fold_train, N_TRAIN, input_length, output_length)\n",
    "X_test, y_test = get_X_y(fold_test, N_TEST, input_length, output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd47c85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "842a1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fold in folds:\n",
    "#    fold_train, fold_test = train_test_split(fold, TRAIN_TEST_RATIO, input_length)\n",
    "#    return fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110fbc3",
   "metadata": {},
   "source": [
    "# RNN Model (one fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "643122bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train):\n",
    "    \n",
    "    # $CHALLENGIFY_BEGIN    \n",
    "    \n",
    "    # 0 - Normalization\n",
    "    # ======================    \n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train)\n",
    "    \n",
    "    # 1 - RNN architecture\n",
    "    # ======================    \n",
    "    model = Sequential()\n",
    "    ## 1.0 - All the rows will be standardized through the already adapted normalization layer\n",
    "    model.add(normalizer)\n",
    "    ## 1.1 - Recurrent Layer\n",
    "    model.add(LSTM(64, \n",
    "                          activation='tanh', \n",
    "                          return_sequences = False,\n",
    "                          recurrent_dropout = 0.3))\n",
    "    ## 1.2 - Predictive Dense Layers\n",
    "    output_length = y_train.shape[1]\n",
    "    model.add(Dense(output_length, activation='linear'))\n",
    "\n",
    "    # 2 - Compiler\n",
    "    # ======================    \n",
    "    adam = optimizers.Adam(learning_rate=0.02)    \n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebaf5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, verbose=1):\n",
    "\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    es = EarlyStopping(monitor = \"val_loss\",\n",
    "                      patience = 3,\n",
    "                      mode = \"min\",\n",
    "                      restore_best_weights = True)\n",
    "\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split = 0.3,\n",
    "                        shuffle = False,\n",
    "                        batch_size = 32,\n",
    "                        epochs = 50,\n",
    "                        callbacks = [es],\n",
    "                        verbose = verbose)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2adb0dcf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 16:21:03.572387: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, None, 25)         51        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                23040     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,156\n",
      "Trainable params: 23,105\n",
      "Non-trainable params: 51\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 266ms/step - loss: 18.7985 - mae: 3.2741 - val_loss: 8.0692 - val_mae: 2.2104\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 13.2107 - mae: 2.7495 - val_loss: 7.6796 - val_mae: 2.0337\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 10.7702 - mae: 2.3931 - val_loss: 3.7812 - val_mae: 1.4254\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.2298 - mae: 1.7868 - val_loss: 1.7542 - val_mae: 1.0993\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.9381 - mae: 1.2302 - val_loss: 0.7060 - val_mae: 0.6684\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5920 - mae: 0.8518 - val_loss: 1.0675 - val_mae: 0.7832\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9356 - mae: 0.6733 - val_loss: 2.0005 - val_mae: 1.2549\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2371 - mae: 0.8609 - val_loss: 0.8132 - val_mae: 0.6067\n"
     ]
    }
   ],
   "source": [
    "# 1 - Initialising the RNN model\n",
    "# ====================================\n",
    "\n",
    "model = init_model(X_train, y_train)\n",
    "model.summary()\n",
    "\n",
    "# 2 - Training\n",
    "# ====================================\n",
    "model, history = fit_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e45702f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 64.4005 - mae: 7.2036\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6df94d",
   "metadata": {},
   "source": [
    "# Baseline Model (for one fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aae6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_baseline():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x[:,-1,1,None]))\n",
    "\n",
    "    adam = optimizers.Adam(learning_rate=0.02)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8dde757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 130.8991 - mae: 8.3885\n"
     ]
    }
   ],
   "source": [
    "baseline_model = init_baseline()\n",
    "baseline_score = baseline_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc39781",
   "metadata": {},
   "source": [
    "# Cross-validation (all folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4f450ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_baseline_and_lstm():\n",
    "    '''\n",
    "    This function cross-validates \n",
    "    - the \"last seen value\" baseline model\n",
    "    - the RNN model\n",
    "    '''\n",
    "    \n",
    "    list_of_mae_baseline_model = []\n",
    "    list_of_mae_recurrent_model = []\n",
    "    \n",
    "    # 0 - Creating folds\n",
    "    # =========================================    \n",
    "    folds = get_folds(df_station_377, FOLD_LENGTH, FOLD_STRIDE)\n",
    "    \n",
    "    for fold_id, fold in enumerate(folds):\n",
    "        \n",
    "        # 1 - Train/Test split the current fold\n",
    "        # =========================================\n",
    "        (fold_train, fold_test) = train_test_split(fold, TRAIN_TEST_RATIO, input_length)                   \n",
    "\n",
    "        X_train, y_train = get_X_y(fold_train, N_TRAIN, input_length, output_length)\n",
    "        X_test, y_test = get_X_y(fold_test, N_TEST, input_length, output_length)\n",
    "        \n",
    "        # 2 - Modelling\n",
    "        # =========================================\n",
    "        \n",
    "        ##### Baseline Model\n",
    "        baseline_model = init_baseline()\n",
    "        \n",
    "        print(type(X_test[0,0,0]))\n",
    "        \n",
    "        mae_baseline = baseline_model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "        list_of_mae_baseline_model.append(mae_baseline)\n",
    "        print(\"-\"*50)\n",
    "        print(f\"MAE baseline fold n°{fold_id} = {round(mae_baseline, 2)}\")\n",
    "\n",
    "        ##### LSTM Model\n",
    "        model = init_model(X_train, y_train)\n",
    "        es = EarlyStopping(monitor = \"val_mae\",\n",
    "                           mode = \"min\",\n",
    "                           patience = 2, \n",
    "                           restore_best_weights = True)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_split = 0.3,\n",
    "                            shuffle = False,\n",
    "                            batch_size = 32,\n",
    "                            epochs = 50,\n",
    "                            callbacks = [es],\n",
    "                            verbose = 0)\n",
    "        res = model.evaluate(X_test, y_test, verbose=0)\n",
    "        mae_lstm = res[1]\n",
    "        list_of_mae_recurrent_model.append(mae_lstm)\n",
    "        print(f\"MAE LSTM fold n°{fold_id} = {round(mae_lstm, 2)}\")\n",
    "        \n",
    "        ##### Comparison LSTM vs Baseline for the current fold\n",
    "        print(f\"🏋🏽‍♂️ improvement over baseline: {round((1 - (mae_lstm/mae_baseline))*100,2)} % \\n\")\n",
    "\n",
    "    return list_of_mae_baseline_model, list_of_mae_recurrent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d6ca1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []\n",
    "for i in df_list:\n",
    "                      \n",
    "\n",
    "    X_train, y_train = get_X_y(i, N_TRAIN, input_length, output_length)\n",
    "    X_test, y_test = get_X_y(i, N_TEST, input_length, output_length)\n",
    "\n",
    "    # 2 - Modelling\n",
    "    # =========================================\n",
    "\n",
    "    ##### LSTM Model\n",
    "    model = init_model(X_train, y_train)\n",
    "    es = EarlyStopping(monitor = \"val_mae\",\n",
    "                       mode = \"min\",\n",
    "                       patience = 2, \n",
    "                       restore_best_weights = True)\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split = 0.3,\n",
    "                        shuffle = False,\n",
    "                        batch_size = 32,\n",
    "                        epochs = 50,\n",
    "                        callbacks = [es],\n",
    "                        verbose = 0)\n",
    "    res = model.evaluate(X_test, y_test, verbose=0)\n",
    "    mae_lstm = res[1]\n",
    "    mae_list.append(mae_lstm)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c873a107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.079939365386963,\n",
       " 2.7373292446136475,\n",
       " 2.183718204498291,\n",
       " 13.436391830444336,\n",
       " 4.472980976104736,\n",
       " 7.5922532081604,\n",
       " 6.412288665771484,\n",
       " 2.9414238929748535,\n",
       " 13.4185209274292,\n",
       " 4.35196590423584,\n",
       " 3.3075268268585205,\n",
       " 7.084357261657715,\n",
       " 4.481198787689209,\n",
       " 3.043718099594116,\n",
       " 2.8073012828826904,\n",
       " 4.4678802490234375,\n",
       " 3.1924681663513184,\n",
       " 3.1045684814453125,\n",
       " 7.727598667144775,\n",
       " 4.149720668792725,\n",
       " 3.5571722984313965,\n",
       " 2.620628833770752,\n",
       " 3.82080340385437,\n",
       " 6.596154689788818,\n",
       " 3.2003378868103027,\n",
       " 4.790660381317139,\n",
       " 9.98023509979248,\n",
       " 4.216279029846191,\n",
       " 6.139786243438721,\n",
       " 7.0306549072265625,\n",
       " 8.084578514099121,\n",
       " 2.001192569732666,\n",
       " 1.7682855129241943,\n",
       " 12.33507251739502,\n",
       " 2.7202868461608887,\n",
       " 3.6841368675231934,\n",
       " 2.7075271606445312,\n",
       " 3.4725775718688965,\n",
       " 8.158315658569336,\n",
       " 2.88555908203125,\n",
       " 2.2327446937561035,\n",
       " 2.9615254402160645,\n",
       " 2.284156322479248,\n",
       " 3.839937686920166,\n",
       " 13.681694030761719,\n",
       " 4.059967994689941,\n",
       " 2.563697338104248,\n",
       " 3.753520965576172,\n",
       " 8.57215690612793,\n",
       " 7.209758758544922,\n",
       " 2.8122763633728027,\n",
       " 3.4433951377868652,\n",
       " 5.739528656005859,\n",
       " 9.745485305786133,\n",
       " 2.2985358238220215,\n",
       " 4.556784629821777,\n",
       " 2.9193599224090576,\n",
       " 11.358591079711914,\n",
       " 6.4693603515625,\n",
       " 6.789238929748535,\n",
       " 6.943085670471191,\n",
       " 8.137458801269531,\n",
       " 3.695695400238037,\n",
       " 2.960369348526001,\n",
       " 5.001540660858154,\n",
       " 6.312845230102539,\n",
       " 4.588375091552734,\n",
       " 10.27990436553955,\n",
       " 6.304837226867676,\n",
       " 3.4131805896759033,\n",
       " 5.298506259918213,\n",
       " 3.566770553588867,\n",
       " 10.250028610229492,\n",
       " 3.445378065109253,\n",
       " 1.6991233825683594,\n",
       " 4.9459228515625,\n",
       " 6.02794075012207,\n",
       " 3.206789016723633,\n",
       " 5.2970805168151855,\n",
       " 2.654808759689331,\n",
       " 4.450936794281006,\n",
       " 7.697447776794434,\n",
       " 3.6345081329345703,\n",
       " 20.02518653869629,\n",
       " 5.552952766418457,\n",
       " 4.7184624671936035,\n",
       " 5.897922039031982,\n",
       " 5.662764549255371,\n",
       " 2.5222434997558594,\n",
       " 8.006760597229004,\n",
       " 5.885825157165527,\n",
       " 9.771505355834961,\n",
       " 4.705737590789795,\n",
       " 6.001861572265625,\n",
       " 4.723230838775635,\n",
       " 2.71500825881958,\n",
       " 4.582451820373535,\n",
       " 2.402646541595459,\n",
       " 7.5729498863220215,\n",
       " 5.358490943908691,\n",
       " 3.382417678833008,\n",
       " 7.360151767730713,\n",
       " 10.167885780334473,\n",
       " 1.822076439857483,\n",
       " 3.544788360595703,\n",
       " 7.8791184425354,\n",
       " 15.105517387390137,\n",
       " 6.144519805908203,\n",
       " 5.107742786407471,\n",
       " 2.1248764991760254,\n",
       " 4.5252485275268555,\n",
       " 5.959050178527832,\n",
       " 7.997467041015625,\n",
       " 3.9669432640075684,\n",
       " 3.4609882831573486,\n",
       " 17.157318115234375,\n",
       " 6.6887383460998535,\n",
       " 6.3775153160095215,\n",
       " 21.926746368408203,\n",
       " 4.695333957672119,\n",
       " 4.642233848571777,\n",
       " 8.786611557006836,\n",
       " 3.4470043182373047,\n",
       " 5.796751499176025,\n",
       " 26.239370346069336,\n",
       " 9.121088981628418,\n",
       " 4.217067718505859,\n",
       " 9.420663833618164,\n",
       " 3.707862377166748,\n",
       " 3.701235294342041,\n",
       " 4.311192512512207,\n",
       " 15.42815113067627,\n",
       " 3.225501298904419,\n",
       " 3.032442092895508,\n",
       " 9.10779857635498,\n",
       " 5.157292366027832,\n",
       " 4.111267566680908,\n",
       " 5.95141077041626,\n",
       " 3.8482184410095215,\n",
       " 7.0138654708862305,\n",
       " 8.232339859008789,\n",
       " 8.939123153686523,\n",
       " 4.287264823913574,\n",
       " 2.7885537147521973,\n",
       " 12.155275344848633,\n",
       " 4.646872043609619,\n",
       " 4.032074928283691,\n",
       " 1.4646552801132202,\n",
       " 9.041875839233398,\n",
       " 2.8287999629974365,\n",
       " 2.2027294635772705,\n",
       " 3.0879013538360596,\n",
       " 4.088173866271973,\n",
       " 9.052764892578125,\n",
       " 3.4751639366149902,\n",
       " 8.121376037597656,\n",
       " 5.968472003936768,\n",
       " 14.289563179016113,\n",
       " 2.7682998180389404,\n",
       " 6.6443352699279785,\n",
       " 2.6109097003936768,\n",
       " 6.175472736358643,\n",
       " 4.4765729904174805,\n",
       " 5.858842372894287,\n",
       " 2.4923477172851562,\n",
       " 3.9835193157196045,\n",
       " 6.253892421722412,\n",
       " 5.883760452270508,\n",
       " 2.7801990509033203,\n",
       " 5.305407524108887,\n",
       " 2.203282594680786,\n",
       " 1.913602590560913,\n",
       " 2.5668838024139404,\n",
       " 5.001364707946777,\n",
       " 6.629534721374512,\n",
       " 9.76690673828125,\n",
       " 19.18221664428711,\n",
       " 5.276320457458496,\n",
       " 2.5535404682159424,\n",
       " 8.591876029968262,\n",
       " 32.679595947265625,\n",
       " 14.743528366088867,\n",
       " 4.971041202545166,\n",
       " 4.663532257080078,\n",
       " 3.816812038421631,\n",
       " 4.4658522605896,\n",
       " 3.521122694015503,\n",
       " 3.110740900039673,\n",
       " 2.2337348461151123,\n",
       " 10.770434379577637,\n",
       " 9.695694923400879,\n",
       " 6.9651618003845215,\n",
       " 4.239048480987549,\n",
       " 2.0256686210632324,\n",
       " 2.2879106998443604,\n",
       " 3.1629741191864014,\n",
       " 2.844792604446411,\n",
       " 3.2702643871307373,\n",
       " 4.530787467956543,\n",
       " 6.603089809417725,\n",
       " 3.8427367210388184,\n",
       " 6.353737831115723,\n",
       " 2.8390471935272217,\n",
       " 3.149026870727539,\n",
       " 5.388140678405762,\n",
       " 2.9296715259552,\n",
       " 5.480557918548584,\n",
       " 4.086891174316406,\n",
       " 4.021183967590332,\n",
       " 3.3859291076660156,\n",
       " 17.52017593383789,\n",
       " 8.543998718261719,\n",
       " 14.091404914855957,\n",
       " 3.176666736602783,\n",
       " 2.092341899871826,\n",
       " 2.6893181800842285,\n",
       " 3.5642361640930176,\n",
       " 2.680232524871826,\n",
       " 3.5313048362731934,\n",
       " 2.671501874923706,\n",
       " 8.84959602355957,\n",
       " 4.316210746765137,\n",
       " 3.1982789039611816,\n",
       " 11.180191040039062,\n",
       " 10.179040908813477,\n",
       " 5.925458908081055,\n",
       " 10.468595504760742,\n",
       " 8.523292541503906,\n",
       " 2.638603687286377,\n",
       " 7.293648719787598,\n",
       " 4.6026411056518555,\n",
       " 5.287981986999512,\n",
       " 3.1145260334014893,\n",
       " 4.761361122131348,\n",
       " 10.06632137298584,\n",
       " 1.9050095081329346,\n",
       " 4.062212944030762,\n",
       " 9.883460998535156,\n",
       " 3.4807658195495605,\n",
       " 5.655118465423584,\n",
       " 4.431344509124756,\n",
       " 3.0464413166046143,\n",
       " 7.198174476623535,\n",
       " 4.334490776062012,\n",
       " 1.795519232749939,\n",
       " 3.7796454429626465,\n",
       " 1.7993526458740234,\n",
       " 3.1566600799560547,\n",
       " 9.551321029663086,\n",
       " 3.4892821311950684,\n",
       " 1.6398086547851562,\n",
       " 3.6435418128967285,\n",
       " 5.090666770935059,\n",
       " 12.729991912841797,\n",
       " 3.9393553733825684,\n",
       " 2.3150620460510254,\n",
       " 4.350541114807129,\n",
       " 2.613616466522217,\n",
       " 2.4305367469787598,\n",
       " 3.7539572715759277,\n",
       " 2.978565216064453,\n",
       " 3.009580135345459,\n",
       " 3.939519166946411,\n",
       " 3.0123629570007324,\n",
       " 6.3050713539123535,\n",
       " 1.5385982990264893,\n",
       " 7.6417236328125,\n",
       " 3.3906795978546143,\n",
       " 2.9254329204559326,\n",
       " 1.7926108837127686,\n",
       " 4.557811737060547,\n",
       " 2.116290330886841,\n",
       " 3.625457286834717,\n",
       " 3.8947105407714844,\n",
       " 5.958958625793457,\n",
       " 4.651037216186523,\n",
       " 2.6801483631134033,\n",
       " 1.0955089330673218,\n",
       " 2.5487403869628906]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f608fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for i in df_list:\n",
    "                      \n",
    "\n",
    "    X_train, y_train = get_X_y(i, N_TRAIN, input_length, output_length)\n",
    "    X_test, y_test = get_X_y(i, N_TEST, input_length, output_length)\n",
    "\n",
    "    prediction_test = model.predict(X_test[10])\n",
    "    \n",
    "    pred_list.append(int(prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b37553f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46210e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d1b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad71295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edd1452b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°0 = 8.86\n",
      "MAE LSTM fold n°0 = 7.29\n",
      "🏋🏽‍♂️ improvement over baseline: 17.69 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°1 = 7.95\n",
      "MAE LSTM fold n°1 = 6.1\n",
      "🏋🏽‍♂️ improvement over baseline: 23.3 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°2 = 14.84\n",
      "MAE LSTM fold n°2 = 9.35\n",
      "🏋🏽‍♂️ improvement over baseline: 37.02 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°3 = 14.97\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x292252290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAE LSTM fold n°3 = 17.76\n",
      "🏋🏽‍♂️ improvement over baseline: -18.68 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°4 = 19.9\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x296b5a7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAE LSTM fold n°4 = 12.59\n",
      "🏋🏽‍♂️ improvement over baseline: 36.74 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°5 = 12.79\n",
      "MAE LSTM fold n°5 = 5.35\n",
      "🏋🏽‍♂️ improvement over baseline: 58.2 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°6 = 13.98\n",
      "MAE LSTM fold n°6 = 8.68\n",
      "🏋🏽‍♂️ improvement over baseline: 37.86 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°7 = 20.47\n",
      "MAE LSTM fold n°7 = 10.63\n",
      "🏋🏽‍♂️ improvement over baseline: 48.06 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°8 = 16.86\n",
      "MAE LSTM fold n°8 = 7.08\n",
      "🏋🏽‍♂️ improvement over baseline: 58.01 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°9 = 12.19\n",
      "MAE LSTM fold n°9 = 7.88\n",
      "🏋🏽‍♂️ improvement over baseline: 35.36 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°10 = 8.89\n",
      "MAE LSTM fold n°10 = 4.16\n",
      "🏋🏽‍♂️ improvement over baseline: 53.17 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°11 = 7.7\n",
      "MAE LSTM fold n°11 = 4.62\n",
      "🏋🏽‍♂️ improvement over baseline: 39.93 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°12 = 7.4\n",
      "MAE LSTM fold n°12 = 4.73\n",
      "🏋🏽‍♂️ improvement over baseline: 36.04 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°13 = 8.57\n",
      "MAE LSTM fold n°13 = 7.71\n",
      "🏋🏽‍♂️ improvement over baseline: 10.03 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°14 = 5.18\n",
      "MAE LSTM fold n°14 = 4.83\n",
      "🏋🏽‍♂️ improvement over baseline: 6.79 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°15 = 3.25\n",
      "MAE LSTM fold n°15 = 4.42\n",
      "🏋🏽‍♂️ improvement over baseline: -35.94 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°16 = 4.02\n",
      "MAE LSTM fold n°16 = 1.75\n",
      "🏋🏽‍♂️ improvement over baseline: 56.32 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°17 = 4.01\n",
      "MAE LSTM fold n°17 = 2.54\n",
      "🏋🏽‍♂️ improvement over baseline: 36.51 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°18 = 2.42\n",
      "MAE LSTM fold n°18 = 1.46\n",
      "🏋🏽‍♂️ improvement over baseline: 39.72 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°19 = 3.28\n",
      "MAE LSTM fold n°19 = 1.53\n",
      "🏋🏽‍♂️ improvement over baseline: 53.55 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°20 = 4.88\n",
      "MAE LSTM fold n°20 = 2.4\n",
      "🏋🏽‍♂️ improvement over baseline: 50.96 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°21 = 3.55\n",
      "MAE LSTM fold n°21 = 2.45\n",
      "🏋🏽‍♂️ improvement over baseline: 31.0 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°22 = 3.2\n",
      "MAE LSTM fold n°22 = 5.51\n",
      "🏋🏽‍♂️ improvement over baseline: -72.18 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°23 = 4.18\n",
      "MAE LSTM fold n°23 = 4.33\n",
      "🏋🏽‍♂️ improvement over baseline: -3.65 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°24 = 4.35\n",
      "MAE LSTM fold n°24 = 3.72\n",
      "🏋🏽‍♂️ improvement over baseline: 14.5 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°25 = 8.1\n",
      "MAE LSTM fold n°25 = 9.75\n",
      "🏋🏽‍♂️ improvement over baseline: -20.4 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°26 = 10.18\n",
      "MAE LSTM fold n°26 = 8.78\n",
      "🏋🏽‍♂️ improvement over baseline: 13.72 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°27 = 12.75\n",
      "MAE LSTM fold n°27 = 2.89\n",
      "🏋🏽‍♂️ improvement over baseline: 77.33 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°28 = 8.44\n",
      "MAE LSTM fold n°28 = 3.63\n",
      "🏋🏽‍♂️ improvement over baseline: 56.96 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°29 = 9.11\n",
      "MAE LSTM fold n°29 = 4.63\n",
      "🏋🏽‍♂️ improvement over baseline: 49.24 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°30 = 11.34\n",
      "MAE LSTM fold n°30 = 3.84\n",
      "🏋🏽‍♂️ improvement over baseline: 66.18 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°31 = 16.44\n",
      "MAE LSTM fold n°31 = 8.51\n",
      "🏋🏽‍♂️ improvement over baseline: 48.25 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°32 = 9.22\n",
      "MAE LSTM fold n°32 = 8.49\n",
      "🏋🏽‍♂️ improvement over baseline: 7.99 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°33 = 12.35\n",
      "MAE LSTM fold n°33 = 11.46\n",
      "🏋🏽‍♂️ improvement over baseline: 7.2 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°34 = 9.76\n",
      "MAE LSTM fold n°34 = 5.02\n",
      "🏋🏽‍♂️ improvement over baseline: 48.59 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°35 = 4.59\n",
      "MAE LSTM fold n°35 = 10.59\n",
      "🏋🏽‍♂️ improvement over baseline: -130.62 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°36 = 3.51\n",
      "MAE LSTM fold n°36 = 3.61\n",
      "🏋🏽‍♂️ improvement over baseline: -2.63 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°37 = 3.53\n",
      "MAE LSTM fold n°37 = 8.06\n",
      "🏋🏽‍♂️ improvement over baseline: -128.75 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°38 = 4.35\n",
      "MAE LSTM fold n°38 = 3.26\n",
      "🏋🏽‍♂️ improvement over baseline: 24.91 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°39 = 2.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE LSTM fold n°39 = 3.09\n",
      "🏋🏽‍♂️ improvement over baseline: -24.2 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°40 = 1.84\n",
      "WARNING:tensorflow:5 out of the last 22 calls to <function Model.make_test_function.<locals>.test_function at 0x292253f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAE LSTM fold n°40 = 2.4\n",
      "🏋🏽‍♂️ improvement over baseline: -30.26 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°41 = 11.02\n",
      "MAE LSTM fold n°41 = 1.67\n",
      "🏋🏽‍♂️ improvement over baseline: 84.83 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°42 = 10.12\n",
      "MAE LSTM fold n°42 = 1.45\n",
      "🏋🏽‍♂️ improvement over baseline: 85.68 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°43 = 17.25\n",
      "MAE LSTM fold n°43 = 4.62\n",
      "🏋🏽‍♂️ improvement over baseline: 73.22 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°44 = 1.97\n",
      "MAE LSTM fold n°44 = 2.48\n",
      "🏋🏽‍♂️ improvement over baseline: -25.96 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°45 = 4.63\n",
      "MAE LSTM fold n°45 = 4.43\n",
      "🏋🏽‍♂️ improvement over baseline: 4.14 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°46 = 4.56\n",
      "MAE LSTM fold n°46 = 2.63\n",
      "🏋🏽‍♂️ improvement over baseline: 42.22 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°47 = 5.49\n",
      "MAE LSTM fold n°47 = 4.16\n",
      "🏋🏽‍♂️ improvement over baseline: 24.2 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°48 = 5.5\n",
      "MAE LSTM fold n°48 = 5.47\n",
      "🏋🏽‍♂️ improvement over baseline: 0.63 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°49 = 2.54\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x292253c70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAE LSTM fold n°49 = 2.98\n",
      "🏋🏽‍♂️ improvement over baseline: -17.44 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°50 = 4.05\n",
      "MAE LSTM fold n°50 = 4.38\n",
      "🏋🏽‍♂️ improvement over baseline: -8.17 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°51 = 7.51\n",
      "MAE LSTM fold n°51 = 6.74\n",
      "🏋🏽‍♂️ improvement over baseline: 10.16 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°52 = 11.41\n",
      "MAE LSTM fold n°52 = 4.91\n",
      "🏋🏽‍♂️ improvement over baseline: 56.95 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°53 = 13.97\n",
      "MAE LSTM fold n°53 = 5.18\n",
      "🏋🏽‍♂️ improvement over baseline: 62.93 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°54 = 14.41\n",
      "MAE LSTM fold n°54 = 3.93\n",
      "🏋🏽‍♂️ improvement over baseline: 72.73 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°55 = 13.66\n",
      "MAE LSTM fold n°55 = 4.19\n",
      "🏋🏽‍♂️ improvement over baseline: 69.37 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°56 = 9.09\n",
      "MAE LSTM fold n°56 = 5.85\n",
      "🏋🏽‍♂️ improvement over baseline: 35.68 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°57 = 11.56\n",
      "MAE LSTM fold n°57 = 8.36\n",
      "🏋🏽‍♂️ improvement over baseline: 27.71 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°58 = 8.42\n",
      "MAE LSTM fold n°58 = 8.76\n",
      "🏋🏽‍♂️ improvement over baseline: -4.06 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°59 = 12.07\n",
      "MAE LSTM fold n°59 = 7.5\n",
      "🏋🏽‍♂️ improvement over baseline: 37.89 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°60 = 9.42\n",
      "MAE LSTM fold n°60 = 4.2\n",
      "🏋🏽‍♂️ improvement over baseline: 55.43 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°61 = 3.41\n",
      "MAE LSTM fold n°61 = 7.04\n",
      "🏋🏽‍♂️ improvement over baseline: -106.25 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°62 = 9.9\n",
      "MAE LSTM fold n°62 = 5.85\n",
      "🏋🏽‍♂️ improvement over baseline: 40.89 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°63 = 2.49\n",
      "MAE LSTM fold n°63 = 1.66\n",
      "🏋🏽‍♂️ improvement over baseline: 33.27 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°64 = 10.39\n",
      "MAE LSTM fold n°64 = 2.14\n",
      "🏋🏽‍♂️ improvement over baseline: 79.42 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°65 = 10.1\n",
      "MAE LSTM fold n°65 = 0.87\n",
      "🏋🏽‍♂️ improvement over baseline: 91.39 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°66 = 5.78\n",
      "MAE LSTM fold n°66 = 0.7\n",
      "🏋🏽‍♂️ improvement over baseline: 87.92 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°67 = 5.75\n",
      "MAE LSTM fold n°67 = 0.85\n",
      "🏋🏽‍♂️ improvement over baseline: 85.28 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°68 = 6.18\n",
      "MAE LSTM fold n°68 = 0.94\n",
      "🏋🏽‍♂️ improvement over baseline: 84.74 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°69 = 4.76\n",
      "MAE LSTM fold n°69 = 1.07\n",
      "🏋🏽‍♂️ improvement over baseline: 77.59 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°70 = 2.66\n",
      "MAE LSTM fold n°70 = 2.66\n",
      "🏋🏽‍♂️ improvement over baseline: -0.01 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°71 = 2.33\n",
      "MAE LSTM fold n°71 = 1.86\n",
      "🏋🏽‍♂️ improvement over baseline: 20.09 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°72 = 4.2\n",
      "MAE LSTM fold n°72 = 2.68\n",
      "🏋🏽‍♂️ improvement over baseline: 36.13 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°73 = 7.11\n",
      "MAE LSTM fold n°73 = 2.46\n",
      "🏋🏽‍♂️ improvement over baseline: 65.44 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°74 = 9.54\n",
      "MAE LSTM fold n°74 = 5.1\n",
      "🏋🏽‍♂️ improvement over baseline: 46.57 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°75 = 11.83\n",
      "MAE LSTM fold n°75 = 3.77\n",
      "🏋🏽‍♂️ improvement over baseline: 68.14 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°76 = 10.41\n",
      "MAE LSTM fold n°76 = 3.48\n",
      "🏋🏽‍♂️ improvement over baseline: 66.6 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°77 = 13.32\n",
      "MAE LSTM fold n°77 = 3.24\n",
      "🏋🏽‍♂️ improvement over baseline: 75.69 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°78 = 10.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE LSTM fold n°78 = 1.53\n",
      "🏋🏽‍♂️ improvement over baseline: 85.55 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°79 = 11.36\n",
      "MAE LSTM fold n°79 = 1.93\n",
      "🏋🏽‍♂️ improvement over baseline: 83.05 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°80 = 7.37\n",
      "MAE LSTM fold n°80 = 2.24\n",
      "🏋🏽‍♂️ improvement over baseline: 69.63 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°81 = 6.98\n",
      "MAE LSTM fold n°81 = 3.89\n",
      "🏋🏽‍♂️ improvement over baseline: 44.35 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°82 = 6.18\n",
      "MAE LSTM fold n°82 = 2.77\n",
      "🏋🏽‍♂️ improvement over baseline: 55.17 % \n",
      "\n",
      "<class 'numpy.float64'>\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°83 = 3.55\n",
      "MAE LSTM fold n°83 = 3.39\n",
      "🏋🏽‍♂️ improvement over baseline: 4.57 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mae_baselines, mae_lstms = cross_validate_baseline_and_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb2b7e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average percentage improvement over baseline = 31.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"average percentage improvement over baseline = {round(np.mean(1 - (np.array(mae_lstms)/np.array(mae_baselines))),2)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fb5a4",
   "metadata": {},
   "source": [
    "# Prediction for one station on date x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a23f440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5, 25)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca2d6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None), dtype=tf.float32, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 25).\n",
      "1/1 [==============================] - 0s 162ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc343cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ca6587f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-15]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce42da",
   "metadata": {},
   "source": [
    "# 9 Prediction for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e38045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_station_377.set_index('Date', inplace=True)\n",
    "#df_station_377 = df_station_377.drop(columns=['Trips_in','Trips_out', 'Unnamed: 0', 'Station_Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ab045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in range(len())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
